---
title: "coachella_aspen"
author: "ricardo_piedrahita"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    self_contained: yes
    code_folding: hide
---

# Load


```{r setup, include=TRUE,echo=TRUE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.width = 8, fig.height = 4)

graphics.off()
email = 0 # Set to 1 to send out (only rp has permissions, others will fail)
## Analyze Coachella ASPEN data
# Import data, perform QAQC check.  If email == 1, send an email out.
#Set directory with this file as the working directory.
# Saving all output to the shared field folder.  Code remains separate/isolated.
dir.create("~/Dropbox/Coachella Field/Data/processing/tester",showWarnings = F)
dir.create("~/Dropbox/Coachella Field/Data/processing/odk data",showWarnings = F)  #Put odk data downloads into here.
dir.create("~/Dropbox/Coachella Field/Data/processing/plots",showWarnings = F)
dir.create("~/Dropbox/Coachella Field/Data/processing/processed data",showWarnings = F)
dir.create("~/Dropbox/Coachella Field/Data/processing/QA Reports",showWarnings = F)
dir.create("~/Dropbox/Coachella Field/Data/processing/results",showWarnings = F)


#Keys: instrument_id, location, size

source('r_scripts/load.R')
source('r_scripts/ASPEN_functions.R')
email = 0 #Set to 1 to send out summary qaqc email, else 0


```

# Import data

```{r import, include=TRUE,echo=TRUE}


#Import Excel meta data (instrument start/stop times, filter IDs, etc.)
field_log = readxl::read_xlsx(list.files(path = "~/Dropbox/Coachella Field/Data",pattern = 'AspenData', recursive = T, full.names = T),
                              skip = 2,col_names  = TRUE,sheet = 'Sample Form Data') %>%
  dplyr::mutate(across(contains("date") | contains("time"), as.character)) %>%
  dplyr::mutate(across(contains("time"), str_remove, "1899-12-31")) %>%
  dplyr::mutate(
    datetime_setup = as.POSIXct(paste(Setup_Date, Setup_Time),
                                tz="America/Los_Angeles"),
    datetime_start = case_when(!is.na(`Programmed Sample Start Date`) ~
                                 as.POSIXct(paste(`Programmed Sample Start Date`,
                                                  `Programmed Sample Start Time`),
                                            format="%Y-%m-%d",
                                            tz="America/Los_Angeles")),
    datetime_end   = case_when(!is.na(`Programmed Sample End Date`) ~
                                 as.POSIXct(paste(`Programmed Sample End Date`,
                                                  `Programmed Sample End Time`),
                                            format="%Y-%m-%d",
                                            tz="America/Los_Angeles"))) %>% 
  dplyr::select(-"Programmed Sample End Date",-"Programmed Sample End Time",-"Programmed Sample Start Date",
                -"Programmed Sample Start Time") %>% 
  tidyr::pivot_longer(cols = c("PM2.5 Quartz Filter ID","PM10 Quartz Filter ID",
                               "PM2.5 Teflon Filter ID","PM10 Teflon Filter ID"),
                      names_to = "Type",
                      values_to="Filter_ID") %>% 
  dplyr::mutate( Filter_Type = ifelse(Type %like% "Quartz","Quartz","Teflon")) %>% 
  dplyr::rename_all(function(x) paste0("excel_", x)) %>% 
  dplyr::mutate(CartridgeID = toupper(excel_Filter_ID),
                excel_Comments = toupper(excel_Comments))


#Import list of filters assembled in Colorado
filter_list = readxl::read_xlsx(list.files(path = "~/Dropbox/Coachella Field/Data",
                                           pattern = 'AspenData', recursive = T, full.names = T),
                                skip = 0,sheet = 'Filter List')[,2:5] 

colnames(filter_list) <-c("FilterID", "FilterType","CartridgeID","DateSent")
filter_list <- filter_list %>% 
  dplyr::filter(!is.na(DateSent)) %>% 
  dplyr::mutate(DateSent = as.Date(DateSent),
                FilterID = toupper(FilterID),
                CartridgeID = toupper(CartridgeID),
                FilterID = case_when(FilterType == "Quartz" ~ paste0(as.character(DateSent),"_",CartridgeID),
                                     TRUE ~ FilterID))
DT::datatable(filter_list,caption="Complete list of filters used in study")

#Import ASPEN data
aspen_files = list.files(path = "~/Dropbox/Coachella Field/Data/Field Data Collected",pattern = 'ASPEN00', recursive = T, full.names = T)
aspen_data = rbindlist(lapply(aspen_files,read_aspen)) 

aspen_files[sapply(aspen_files, file.size) > 10000]


aspen_header <- rbindlist(lapply(aspen_files,read_aspen_header)) %>% 
  as.data.frame() %>% 
  dplyr::rename(Filter1ID = CIDfilter1,
                Filter2ID = CIDfilter2) %>% 
  dplyr::select(ASPENserial,LogFilename,Filter1ID,Filter2ID,Filter1StartDateTimeUTC,Filter2StartDateTimeUTC,EndDateTimeUTC,
                Filter1ShutdownMode,Filter2ShutdownMode,Filter1SampledRuntime,Filter2SampledRuntime,Filter1AverageVolumetricFlowRate,
                Filter2AverageVolumetricFlowRate,Filter1SampledVolume,Filter2SampledVolume) 

aspen_header <- rbind(aspen_header %>% 
                        dplyr::select(ASPENserial,LogFilename,starts_with("Filter1")) %>% 
                        dplyr::mutate(Filter = "Filter1") %>% 
                        dplyr::rename_all(function(x) gsub("Filter1","", x)),
                      aspen_header %>% 
                        dplyr::select(ASPENserial,LogFilename,starts_with("Filter2")) %>% 
                        dplyr::mutate(Filter = "Filter2") %>% 
                        dplyr::rename_all(function(x) gsub("Filter2","", x))) %>% 
  dplyr::rename_all(function(x) paste0("file_", x)) %>% 
  dplyr::rename(CartridgeID = file_ID) %>% 
  dplyr::arrange(file_LogFilename,file_StartDateTimeUTC) %>% 
  dplyr::mutate(file_start_date = as.Date(file_StartDateTimeUTC),
                CartridgeID = toupper(CartridgeID),
                SizeCut = case_when(file_Filter %like% "Filter1" ~ "PM2.5",
                                    file_Filter %like% "Filter2" ~ "PM10",
                                    TRUE ~ "NA")) %>% 
  dplyr::mutate(StartDateTimeLocal = with_tz(file_StartDateTimeUTC, 
                                             tzone="America/Los_Angeles"),
                date_start = date(StartDateTimeLocal)) %>%
  dplyr::filter(date(StartDateTimeLocal) %in% date(field_log$excel_datetime_start) | 
                  hour(StartDateTimeLocal) == 0)



```

# Merge and format data


```{r merge, include=TRUE,echo=TRUE}

#1. Check the filter IDs.  Are they consistent between the log sheet and the instrument?
#2. Check the sample operation - sample duration, flow rate, any error messages.  Done.
#3.  Send this info to Madeleine and Christian and Edgar. Done
#4. Send reminder on how when to ship filters.

#1 Merge file with meta data.  And then with filter List to make sure it exists therein

aspen_header_merged_temp = dplyr::full_join(aspen_header,field_log,by = c("CartridgeID")) %>% 
  dplyr::mutate(volume_flag = case_when(!file_AverageVolumetricFlowRate %between% c(1.8,2.2) ~ 1,
                                        !file_AverageVolumetricFlowRate %between% c(1.8,2.2) ~ 1,
                                        is.na(file_AverageVolumetricFlowRate) | 
                                          is.na(file_AverageVolumetricFlowRate) ~ 0 ),
                meta_filter_merge_flag = ifelse(is.na(excel_Location),1,0),
                duration_flag = ifelse(!file_SampledRuntime %between% c(43.2,52.8),1,0)) %>% 
  dplyr::select(CartridgeID,file_ASPENserial,file_LogFilename,
                file_StartDateTimeUTC,file_start_date,file_ShutdownMode,file_SampledRuntime,
                file_AverageVolumetricFlowRate,file_SampledVolume,excel_datetime_start,
                excel_Comments, excel_Filter_Type,volume_flag,
                meta_filter_merge_flag,duration_flag,SizeCut
                # `excel_Flow measured in 22 PM2.5`,`excel_Flow measured in 22 PM10`,
                # `excel_Flow measured in 27 PM10`,`excel_Flow measured in 22 PM2.5`,`excel_Inlet pieces cleaned with isopropyl alcohol?`,
  ) 

aspen_header_merged1 <- dplyr::left_join(aspen_header_merged_temp,filter_list, by="CartridgeID") %>% 
  dplyr::mutate(excel_sent_datediff = as.Date(DateSent)-as.Date(excel_datetime_start), #This should be negative for all.  And then keep the nearest or NA
                sampletype = case_when(excel_Comments %like% "BLANK" ~ "blank",
                                       TRUE ~ "ambient")) %>%
  dplyr::filter(is.na(file_start_date) | #Keep NA file start dates since some files were not saved.
                  (file_SampledRuntime>2 | sampletype %like% "blank"))  %>% #Runs less than 1 hour are from tests.
  dplyr::mutate(excel_file_datediff = as.Date(excel_datetime_start) - as.Date(file_start_date)) %>% #Should be negative, and nearest!
  dplyr::arrange(CartridgeID,desc(sampletype),file_start_date,excel_file_datediff) %>% 
  dplyr::mutate(R_notes = case_when(excel_sent_datediff>0 ~ "Ensure that the Excel file is up to date, and not merging with another row on Cartridge ID incorrectly.",
                                    excel_file_datediff>0 ~ "ASPEN file may be missing, impute data as possible"))  %>%
  select(FilterID, everything())


aspen_header_merged <- aspen_header_merged1 %>% 
  dplyr::filter(excel_sent_datediff < 0,
                (is.na(excel_file_datediff) | sampletype %like% "blank" | abs(excel_file_datediff) < 2))  %>% #Set to 2 to give some leeway in bad data entry.
  dplyr::group_by(FilterID) %>% 
  dplyr::arrange(desc(excel_sent_datediff)) %>% 
  dplyr::mutate(row_number = row_number()) %>% 
  dplyr::filter(row_number == 1)

DT::datatable(aspen_header_merged,caption = "Merged data set - REVIEW")

# dplyr::filter(1 == row_number())

#These are the rows that get filtered out here.  Should be due to duplicate cartridge IDs for filters that have not yet been sent out- but check anyway!
setdiff(aspen_header_merged1$FilterID,aspen_header_merged$FilterID) 


filename = paste0("~/Dropbox/Coachella Field/Data/QA Reports/Indio_QA_Report_",  Sys.Date(), ".xlsx")
write.xlsx(list(complete_list = aspen_header_merged1,clean_list = aspen_header_merged),file = filename)


if(email == 1){
  source('r_scripts/emailfun.R')
  emailfun(email,filename)
}


```

# Import the analyzed data sets for plotting/analysis

```{r import_processed, include=TRUE,echo=TRUE}

dataGrav = read_xlsx("~/Dropbox/Coachella Source Apportionment PHI/Data/FilterResultsCombined_MR.xlsx",
                     sheet = "Weights_Results",skip = 1) %>% 
  rename_with(., ~ gsub(" ","",.x)) %>% 
  rename_with(., ~ gsub("[[:punct:]]","",.x)) %>% 
  rename("samplevolm3"="Correctedsamplevolumeweightaccountsformissingfiles") %>% 
  dplyr::select(SampleDate,FilterSizeType,SampleType,SampleDurationweight,ErrorNotes,samplevolm3,
                Gravugm3,Gravuncugm3) %>% 
  dplyr::filter(!is.na(Gravugm3))

dataECOC = read_xlsx("~/Dropbox/Coachella Source Apportionment PHI/Data/FilterResultsCombined_MR.xlsx",
                     sheet = "ECOC_Results",skip = 5) %>% 
  rename_with(., ~ gsub(" ","",.x)) %>% 
  rename_with(., ~ gsub("[[:punct:]]","",.x)) %>% 
  dplyr::select(SampleDate,FilterSizeType,
                OCugm3,OCuncugm3,ECugm3,ECuncugm3) %>% 
  dplyr::filter(!is.na(SampleDate))


dataXRF = read_xlsx("~/Dropbox/Coachella Source Apportionment PHI/Data/FilterResultsCombined_MR.xlsx",
                    sheet = "XRF_Results",skip = 3,) %>% 
  rename_with(., ~ gsub(" ","",.x)) %>% 
  rename_with(., ~ gsub("/","",.x)) %>%
  rename_with(., ~ gsub("_","",.x)) %>%
  dplyr::select(-starts_with("ugcm"),-"Correctedsamplevolumexrf(accountsformissingfiles)",-"SampleVolumexrf(m^3)",
                -"Blanksubtractedmassxrf(µg)",-"Sampledurationxrf(hours)",-ErrorNotes,
                -"BlankMass(µg)",-Element,-Detectionlimit,-FilterType,-FilterID,-SampleType,
                -ends_with("ugcm2")) %>% 
  dplyr::filter(!is.na(SampleDate)) %>% 
  dplyr::mutate(FilterSizeType = as.factor(FilterSizeType)) %>% 
  dplyr::mutate_each(funs(if(is.character(.)) as.numeric(.) else .))


dataAll = dataGrav  %>% 
  left_join(dataECOC, by = c("SampleDate","FilterSizeType")) %>% 
  left_join(dataXRF, by = c("SampleDate","FilterSizeType"))

```


# Plot up processed data
```{r plots_processed, include=TRUE,echo=TRUE}

dataLong = dataAll %>% 
  pivot_longer(cols = c(Gravugm3:Pbuncugm3)) %>% 
  dplyr::filter(!is.na(value))


give.n <- function(x){return(c(y = 0, label = length(x)))}
give.meanlog <- function(x){return(c(y =mean(x)+.1, label = round(10^(mean(x)),digits=2)))}

#To make box and whiskers quantiles rather than IQRs.
f <- function(x) {
  r <- quantile(x, probs = c(0.05, 0.25, 0.5, 0.75, 0.95))
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  r
}

distributions25 <- dataLong %>% 
  dplyr::filter(!name %like% "unc") %>% 
  dplyr::filter(!FilterSizeType %like% "10") %>% 
  ggplot(aes(x=name,y=value)) + 
  stat_summary(fun.data = f, geom="boxplot") +  
  stat_summary(fun=mean, colour="blue", geom="point", 
               shape=18, size=3,alpha = 0.8) +
  stat_summary(fun.data = give.meanlog, geom = "text",colour="blue",size=4) +
  geom_jitter(height = 0,width = 0.4,alpha = 0.05) +
  stat_summary(fun.data = give.n, geom = "text") +
  facet_grid(FilterSizeType ~ .) +
  labs(y=expression("µg/m^3"),x="") + 
  ggtitle("Species concentration distributions") + 
  # theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  theme(legend.title = element_blank()) +
  scale_y_log10() 
distributions25

distributions10 <- dataLong %>% 
  dplyr::filter(!name %like% "unc") %>% 
  dplyr::filter(FilterSizeType %like% "10") %>% 
  ggplot(aes(x=name,y=value))+ 
  stat_summary(fun.data = f, geom="boxplot") +  
  stat_summary(fun=mean, colour="blue", geom="point", 
               shape=18, size=3,alpha = 0.8) +
  stat_summary(fun.data = give.meanlog, geom = "text",colour="blue",size=4) +
  geom_jitter(height = 0,width = 0.4,alpha = 0.05) +
  stat_summary(fun.data = give.n, geom = "text") +
  facet_grid(FilterSizeType ~ .) +
  labs(y=expression("µg/m^3"),x="") + 
  ggtitle("Species concentration distributions") + 
  # theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  theme(legend.title = element_blank()) +
  scale_y_log10() 
distributions10

tseries25 <- dataLong %>% 
  dplyr::filter(!name %like% "unc") %>% 
  dplyr::filter(!FilterSizeType %like% "10") %>% 
  ggplot(aes(x=SampleDate,y=value))+ 
  geom_smooth(alpha = 0.25) + 
  geom_point(alpha = 0.25) +
  facet_wrap(name ~ .) +
  labs(y=expression("µg/m^3"),x="") + 
  ggtitle("Indio PM2.5 species concentration time series") + 
  # theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  theme(legend.title = element_blank())
tseries25


tseries10 <- dataLong %>% 
  dplyr::filter(!name %like% "unc") %>% 
  dplyr::filter(FilterSizeType %like% "10") %>% 
  ggplot(aes(x=SampleDate,y=value))+ 
  geom_smooth(alpha = 0.25) + 
  geom_point(alpha = 0.25) +
  facet_wrap(name ~ .) +
  labs(y=expression("µg/m^3"),x="") + 
  ggtitle("Indio PM10 species concentration time series") + 
  # theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  theme(legend.title = element_blank())
tseries25

```



# Save processed data in PMF format
```{r save_processed, include=TRUE,echo=TRUE}

dataConcWide25 = dataLong %>% 
  dplyr::filter(!name %like% "unc") %>% 
  pivot_wider(values_from = value) %>% 
  dplyr::filter(!FilterSizeType %like% "10") %>% 
  dplyr::select(-c("FilterSizeType","SampleType","SampleDurationweight","ErrorNotes","samplevolm3"))
write.csv(dataConcWide25,"pmf formatted data/conc_pm25.csv")

dataConcWide10 = dataLong %>% 
  dplyr::filter(!name %like% "unc") %>% 
  pivot_wider(values_from = value) %>% 
  dplyr::filter(FilterSizeType %like% "10") %>% 
  dplyr::select(-c("FilterSizeType","SampleType","SampleDurationweight","ErrorNotes","samplevolm3"))
write.csv(dataConcWide10,"pmf formatted data/conc_pm10.csv")


dataUncWide25 = dataLong %>% 
  dplyr::filter(name %like% "unc") %>% 
  pivot_wider(values_from = value) %>% 
  dplyr::filter(!FilterSizeType %like% "10") %>% 
  dplyr::select(-c("FilterSizeType","SampleType","SampleDurationweight","ErrorNotes","samplevolm3")) 
write.csv(dataUncWide25,"pmf formatted data/unc_pm25.csv")


dataUncWide10 = dataLong %>% 
  dplyr::filter(name %like% "unc") %>% 
  pivot_wider(values_from = value) %>% 
  dplyr::filter(FilterSizeType %like% "10") %>% 
  dplyr::select(-c("FilterSizeType","SampleType","SampleDurationweight","ErrorNotes","samplevolm3"))
write.csv(dataUncWide10,"pmf formatted data/unc_pm10.csv")

```

